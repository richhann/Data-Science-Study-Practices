comparing the performance of Logistic Regression and K-Nearest Neighbors (KNN) models on a classification task. 

# Reflective Report on Portfolio 2

## Introduction

This report delves into the journey of problem-solving and learning encountered while working on Portfolio 2 as part of the [Data Science Study Practices](https://github.com/richhann/Data-Science-Study-Practices/tree/portfolio-part-2-richhann) on GitHub. The central endeavor was to utilize and compare machine learning models, primarily Logistic Regression and K-Nearest Neighbors (KNN), to analyze a specified dataset, and maintain a well-documented GitHub repository throughout the process.

## Problem Solving and Learning

Throughout the project, data preprocessing and model selection posed significant challenges. The venture into comparing different models based on various performance metrics enriched my understanding of machine learning algorithms and their respective strengths and weaknesses in different scenarios.

## Progression and Future Interests

The practical exposure to real-world data, coupled with a hands-on approach to applying theoretical knowledge, has substantially enhanced my data science proficiency. As I move forward, the intrigue around exploring more complex datasets and experimenting with a broader spectrum of machine learning models continues to grow.

## Discussion Points

### Dataset Choice
The dataset for Portfolio 2 was selected to [provide a brief description of the dataset and its relevance to your project].

### Problem Identification
The primary problem identified was evaluating the performance of Logistic Regression and KNN models in predicting [mention what you were predicting].

### Model Selection
The choice of Logistic Regression and KNN was aimed at comparing a parametric method with a non-parametric method to understand their performance in the given task.

### Insights and Conclusions
The Logistic Regression model exhibited an accuracy of approximately 66.8%, slightly outperforming the KNN model with an accuracy of approximately 61.0%. Despite the Logistic Regression model making more correct predictions overall, the project underscored the struggle in predicting negative ratings with both models, particularly with the KNN model. The high recall for positive ratings in the KNN model indicated its proficiency in correctly identifying positive ratings, albeit possibly at the expense of accurately predicting negative ratings. Conversely, the Logistic Regression model portrayed a better balance between precision and recall, making it slightly better in performance when considering both metrics.

## Additional Points
The insights from this project underscore the importance of model selection based on the nature of the data and the problem at hand. It has also shed light on the potential of exploring other models or ensemble methods to improve the prediction of negative ratings further.
